{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "1. Type `python3 --version` into Terminal. If the output starts with \"Python 3.6\", skip to step 3. **Tensorflow does not yet work with Python 3.7, so you _must_ get Python 3.6.** See https://github.com/tensorflow/tensorflow/issues/20517 for updates on 3.7 support.\n",
    "2. Go to https://www.python.org/downloads/ and click on \"Python 3.6.8\". Scroll down to the Files section and click on \"macOS 64-bit installer\". Run the installer and follow the directions. Repeat step 1 to make sure it has successfully installed. \n",
    "3. Install jupyter notebook, so that you can use this tutorial, by typing the following into Terminal:\n",
    "    `pip3 install jupyter`\n",
    "4. Start the jupyter notebook by typing in Terminal _in the same folder that you have this file_ \n",
    "    `jupyter notebook`\n",
    "    This should open a tab in your web browser with a list of files in the folder. Click on this ipynb file to open it.\n",
    "3. Install the tensorflow machine learning library by typing the following into Terminal:\n",
    "    `pip3 install --upgrade tensorflow`\n",
    "4. Install the keras machine learning library by typing the following into Terminal:\n",
    "    `pip3 install keras`\n",
    "5. Install the libraries we'll need to display the images: `pip3 install numpy matplotlib`\n",
    "6. Test that the keras install worked: Type `python3` into the Terminal. When the `>>>` prompt comes up, type `from keras.models import Sequential`. If you don't get any error output, then it worked. Type Ctrl+d (or close the window) to exit.\n",
    "    * If you get an error like `ModuleNotFoundError: No module named 'theano'` then you need to switch the backend to tensorflow. See the instructions at https://keras.io/backend/ or ask me for help.\n",
    "    * If you get a warning like `/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6` you can ignore it. This is a known (trivial) issue with Tensorflow 1.4 for OSX. See https://github.com/tensorflow/tensorflow/issues/14182 if you'd like more details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Code\n",
    "\n",
    "First, we'll want to import the keras modules we'll be using for our neural network and the numpy and matplotlib modules that we'll be using for displaying our test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "import numpy\n",
    "from matplotlib.pyplot import imshow\n",
    "# tell matplotlib to display images within this notebook\n",
    "%matplotlib inline \n",
    "\n",
    "import math # for fancy weight-generating witchcraft\n",
    "import random # for fancy test image-generating witchcraft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The First Model\n",
    "\n",
    "Next, let's set up the structure of our model. We'll start with a really simple model, with just one convolutional layer that has just one filter. We are going to be using 9x9-pixel grayscale images, so we set the input shape accordingly. If we were using color images with red-green-blue channels, the last dimension would be size three (one for each color) instead of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 3\n",
    "image_size = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = Sequential()\n",
    "model0.add(Conv2D(filters=1, # dimensionality of output\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=1, # shift between kernels\n",
    "                  input_shape=(image_size, image_size, 1))) # dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally at this point, we would compile and train (aka fit) our model, but instead we're going to set the weights manually and then see the output we get on some test images.\n",
    "\n",
    "First, let's take a look at what the randomly generated weights look like, to understand the format that we'll need to use to set the new weights. By changing the parameters of the model above and looking at how it affects the weight structure, we can understand what each weight is connected to (try it!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[-0.42329413]],\n",
       " \n",
       "         [[-0.04221511]],\n",
       " \n",
       "         [[ 0.54156697]]],\n",
       " \n",
       " \n",
       "        [[[ 0.01329654]],\n",
       " \n",
       "         [[ 0.16164595]],\n",
       " \n",
       "         [[ 0.04084301]]],\n",
       " \n",
       " \n",
       "        [[[ 0.17058599]],\n",
       " \n",
       "         [[-0.32953727]],\n",
       " \n",
       "         [[ 0.08904934]]]], dtype=float32), array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model0.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we change the weights so that the filter will capture a certain pattern. We'll explore more about what this means below, but feel free to start generating some guesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 1.]],\n",
       " \n",
       "         [[ 1.]],\n",
       " \n",
       "         [[ 1.]]],\n",
       " \n",
       " \n",
       "        [[[-1.]],\n",
       " \n",
       "         [[-1.]],\n",
       " \n",
       "         [[-1.]]],\n",
       " \n",
       " \n",
       "        [[[-1.]],\n",
       " \n",
       "         [[-1.]],\n",
       " \n",
       "         [[-1.]]]], dtype=float32), array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_num = 0\n",
    "filter_num = 0\n",
    "y = 0\n",
    "for x in range(kernel_size):\n",
    "    weights[layer_num][y][x][0][filter_num] = 1\n",
    "for y in range(1,kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        weights[layer_num][y][x][0][filter_num] = -1\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save those weights back into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.set_weights(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Images\n",
    "\n",
    "Now, let's create some 9x9 images that we will run through our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12a2beac8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image0 = numpy.array([\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "    [128, 0, 128, 255, 128, 0, 128, 255, 128],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image0, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12a37b8d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image1 = numpy.array([\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [128, 128, 128, 128, 128, 128, 128, 128, 128],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image1, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12a4b52e8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAACt1JREFUeJzt3V2IXPUZx/HfrxvF12oh22KT0E2hpKRCGzOkWou02oqi1F70QkGhUtgbtUlpEetdr3pTRC9ECFEr1ColKkhIfYEKttCmTl5aTaKQptEk1WaD+HrRNPr0Yo4lSsj+Z+f89+w8+/1AcGf27Pis+PWcOZ7zH0eEAOT0qa4HAFAPgQOJETiQGIEDiRE4kBiBA4kROJAYgQOJETiQ2JIaL7p06dKYmpqq8dIAJB04cEBHjx71bNtVCXxqakr9fr/GSwOQ1Ov1irbjEB1IjMCBxAgcSIzAgcQIHEiMwIHECBxIrChw21fZfsX2Ptt31B4KQDtmDdz2hKR7JV0tabWkG2yvrj0YgNGV7MHXSdoXEfsj4pikRyVdV3csAG0oCXyZpIMnPD7UPPcxtqdt9233Z2Zm2poPwAhaO8kWERsjohcRvcnJybZeFsAISgI/LGnFCY+XN88BWOBKAn9B0pdsr7R9uqTrJT1ZdywAbZj1dtGIOG77VklPS5qQ9EBE7K4+GYCRFd0PHhFbJW2tPAuAlnElG5AYgQOJETiQGIEDiRE4kBiBA4k5Itp/Ubv9FwXwMREx67ro7MGBxAgcSIzAgcQIHEiMwIHECBxIjMCBxAgcSKxk2eQHbB+x/dJ8DASgPSV78F9LuqryHAAqmDXwiHhe0pvzMAuAlvEeHEisaE22EranJU239XoARld0N5ntKUlbIuLCohflbjKgOu4mAxa5kv9N9oikP0taZfuQ7R/VHwtAG1jwARhTHKIDixyBA4kROJAYgQOJETiQGIEDiRE4kBiBA4kROJAYgQOJETiQGIEDiRE4kBiBA4kROJBYyYIPK2w/Z3uP7d2218/HYABGN+uCD7YvkHRBROywfa6k7ZK+HxF7TvEzLPgAVNbKgg8R8XpE7Gi+flfSXknLRh8PQG1DvQdvVlddI2lbjWEAtKt4XXTb50h6TNKGiHjnJN9nXXRggSldF/00SVskPR0RdxVsz3twoLKS9+AlJ9ks6SFJb0bEhpK/MYED9bUV+Dcl/VHSi5I+bJ6+MyK2nuJnCByorJXA54LAgfpYFx1Y5AgcSIzAgcQIHEiMwIHECBxIjMCBxIqvRR/G2rVr1e/3a7w0AEm9Xq9oO/bgQGIEDiRG4EBiBA4kRuBAYgQOJEbgQGIl66KfYfuvtv/WrIv+i/kYDMDoSi50+Y+kyyPivWZttj/Z/n1E/KXybABGNGvgMVjy5b3m4WnNH1ZsAcZA0Xtw2xO2d0k6IunZiGBddGAMFAUeER9ExNckLZe0zvaFn9zG9rTtvu3+zMxM23MCmIOhzqJHxFuSnpN01Um+tzEiehHRm5ycbGs+ACMoOYs+afv85uszJX1X0su1BwMwupKz6BdIesj2hAb/QfhdRGypOxaANpScRf+7Bh84CGDMcCUbkBiBA4kROJAYgQOJETiQGIEDiRE4kBifDw6MKT4fHFjkCBxIjMCBxAgcSIzAgcQIHEiMwIHEigNvFl7caZvFHoAxMcwefL2kvbUGAdC+0mWTl0u6RtKmuuMAaFPpHvxuSbdL+rDiLABaVrKq6rWSjkTE9lm2+/+66K1NB2Aks95sYvuXkm6SdFzSGZI+LenxiLjxFD/DzSZAZSU3mwx1N5ntb0n6WURcO8t2BA5Uxt1kwCLH/eDAmGIPDixyBA4kRuBAYgQOJEbgQGIEDiRG4EBiBA4kRuBAYgQOJEbgQGIEDiRG4EBiBA4kRuBAYgQOJLakZCPbByS9K+kDSccjoldzKADtKAq88e2IOFptEgCt4xAdSKw08JD0jO3ttqdPtgHrogMLT9Gii7aXRcRh25+V9Kyk2yLi+VNsz6KLQGWtLboYEYebvx6R9ISkdaONBmA+lHx00dm2z/3oa0lXSnqp9mAARldyFv1zkp6w/dH2v42Ip6pOBaAVfPABMKb44ANgkSNwIDECBxIjcCAxAgcSI3AgsWHuJiu2du1a9ftckg7U0uuV3bHNHhxIjMCBxAgcSIzAgcQIHEiMwIHECBxIjMCBxIoCt32+7c22X7a91/YltQcDMLrSK9nukfRURPzA9umSzqo4E4CWzBq47fMkXSbph5IUEcckHas7FoA2lByir5Q0I+lB2zttb2oWX/yYE9dFn5mZaX1QAMMrCXyJpIsk3RcRayS9L+mOT24UERsjohcRvcnJyZbHBDAXJYEfknQoIrY1jzdrEDyABW7WwCPiDUkHba9qnrpC0p6qUwFoRelZ9NskPdycQd8v6eZ6IwFoS1HgEbFLEp8JDowZrmQDEiNwIDECBxIjcCAxAgcSI3AgMQIHEuPzwYExxeeDA4scgQOJETiQGIEDiRE4kBiBA4kROJDYrIHbXmV71wl/3rG9YT6GAzCaoS50sT0h6bCkr0fEq6fYjgtdgMpqXOhyhaR/nCpuAAvHsIFfL+mRGoMAaF/xIXqz4OK/JH0lIv59ku9PS5puHq5tbUIAJ1VyiD5M4NdJuiUirizYlvfgQGVtvwe/QRyeA2OlaA/efBbZa5K+GBFvF2zPHhyorNVD9GEQOFAf94MDixyBA4kROJAYgQOJETiQGIEDiRE4kBiBA4kROJAYgQOJETiQGIEDiRE4kBiBA4kROJBYUeC2f2J7t+2XbD9i+4zagwEYXckHHyyT9GNJvYi4UNKEBqurAljgSg/Rl0g60/YSSWdpsLoqgAVu1sAj4rCkX2mwJtvrkt6OiGdqDwZgdCWH6J+RdJ2klZI+L+ls2zeeZLtp233b/fbHBDAXJYfo35H0z4iYiYj/Snpc0jc+uVFEbIyIXkT02h4SwNyUBP6apIttn2XbGnw+2d66YwFoQ8l78G2SNkvaIenF5mc2Vp4LQAtYFx0YU6yLDixyBA4kRuBAYgQOJEbgQGIEDiRG4EBiSyq97lFJrw6x/dLmZ8YV83dv3H+HYef/QslGVS50GZbt/jhfw8783Rv336HW/ByiA4kROJDYQgl83G9eYf7ujfvvUGX+BfEeHEAdC2UPDqCCTgO3fZXtV2zvs31Hl7PMhe0Vtp+zvadZVnp91zPNhe0J2zttb+l6lmHZPt/2Ztsv295r+5KuZxpG7SXJOwvc9oSkeyVdLWm1pBtsr+5qnjk6LumnEbFa0sWSbhnD30GS1mt8V+m5R9JTEfFlSV/VGP0e87EkeZd78HWS9kXE/og4JulRDRZ3HBsR8XpE7Gi+fleDf7mWdTvVcGwvl3SNpE1dzzIs2+dJukzS/ZIUEcci4q1upxpa1SXJuwx8maSDJzw+pDGL40S2pyStkbSt20mGdrek2yV92PUgc7BS0oykB5u3GJtsn931UKXmY0lyTrK1wPY5kh6TtCEi3ul6nlK2r5V0JCK2dz3LHC2RdJGk+yJijaT3JY3NuZzSJclH0WXghyWtOOHx8ua5sWL7NA3ifjgiHu96niFdKul7tg9o8Bbpctu/6XakoRySdKhZGFQaLA56UYfzDKtoSfJRdBn4C5K+ZHul7dM1OLnwZIfzDK1ZRvp+SXsj4q6u5xlWRPw8IpZHxJQG//z/EBGt7kFqiog3JB20vap56gpJezocaVjVlySvdTfZrCLiuO1bJT2twdnDByJid1fzzNGlkm6S9KLtXc1zd0bE1g5nWmxuk/Rws5PYL+nmjucpFhHbbH+0JPlxSTvV8hVtXMkGJMZJNiAxAgcSI3AgMQIHEiNwIDECBxIjcCAxAgcS+x/Tj/6G2se35gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# third image I added\n",
    "image2 = numpy.array(\n",
    "    ([255]*9, [0]*9,[0]*9) *3,\n",
    "dtype=numpy.uint8)\n",
    "imshow(image2, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Images Through Model\n",
    "\n",
    "The images need to be in a slightly different format for Keras than they do for the imshow command. Right now, they are 9x9 arrays, and we need them to be 9x9x1 -- three dimensional instead of two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for image in [image0, image1, image2]: # You may find it easier to take one of these out, to look at them one at a time\n",
    "    images.append(numpy.resize(image, (image_size, image_size, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we give these images to our model and take a look at what the filter has found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]],\n",
       "\n",
       "        [[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]],\n",
       "\n",
       "        [[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]],\n",
       "\n",
       "        [[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]],\n",
       "\n",
       "        [[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]],\n",
       "\n",
       "        [[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]],\n",
       "\n",
       "        [[ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.],\n",
       "         [ -383.],\n",
       "         [ -256.],\n",
       "         [ -383.],\n",
       "         [ -511.]]],\n",
       "\n",
       "\n",
       "       [[[    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.]],\n",
       "\n",
       "        [[-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.]],\n",
       "\n",
       "        [[ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.]],\n",
       "\n",
       "        [[  381.],\n",
       "         [  381.],\n",
       "         [  381.],\n",
       "         [  381.],\n",
       "         [  381.],\n",
       "         [  381.],\n",
       "         [  381.]],\n",
       "\n",
       "        [[    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.],\n",
       "         [    0.]],\n",
       "\n",
       "        [[-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.],\n",
       "         [-1149.]],\n",
       "\n",
       "        [[ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.]]],\n",
       "\n",
       "\n",
       "       [[[  765.],\n",
       "         [  765.],\n",
       "         [  765.],\n",
       "         [  765.],\n",
       "         [  765.],\n",
       "         [  765.],\n",
       "         [  765.]],\n",
       "\n",
       "        [[ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.]],\n",
       "\n",
       "        [[ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.]],\n",
       "\n",
       "        [[  765.],\n",
       "         [  765.],\n",
       "         [  765.],\n",
       "         [  765.],\n",
       "         [  765.],\n",
       "         [  765.],\n",
       "         [  765.]],\n",
       "\n",
       "        [[ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.]],\n",
       "\n",
       "        [[ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.],\n",
       "         [ -765.]],\n",
       "\n",
       "        [[  765.],\n",
       "         [  765.],\n",
       "         [  765.],\n",
       "         [  765.],\n",
       "         [  765.],\n",
       "         [  765.],\n",
       "         [  765.]]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.predict(numpy.array(images))\n",
    "# predict_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions -- Answer these before going on to the second model!\n",
    "1. There are a lot of numbers in the output above: 2 arrays of 7 arrays of 7 arrays of a single element. Why are they in groups of seven?\n",
    "\n",
    "2. When we created the model, we asked it to have one filter. In which image is the filter \"finding\" something? How do you know? How does this relate to the pattern of weights that was set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. With a kernel size of 3 and a stride of 1, 7 kernels can fit horizontally and vertically in the 9x9 image.\\n2. The filter is finding something in the second model. I can tell because there are larger weights. This makes sense\\nbecause the filter is looking for horizontal stripes of some kind:\\n[ 1, 1, 1]\\n[-1,-1,-1]\\n[-1,-1,-1]\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1. With a kernel size of 3 and a stride of 1, 7 kernels can fit horizontally and vertically in the 9x9 image.\n",
    "2. The filter is finding something in the second model. I can tell because there are larger weights. This makes sense\n",
    "because the filter is looking for horizontal stripes of some kind:\n",
    "[ 1, 1, 1]\n",
    "[-1,-1,-1]\n",
    "[-1,-1,-1]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Second Model\n",
    "\n",
    "Let's move to a slightly more complex model. Now, there are two convolutional layers, the first with two filters and the second with one filter. One other difference is that we're going to be taking strides so that we only examine each pixel once, instead of looking at overlapping groups. This makes it a little simpler to understand the manual weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv2D(filters=2,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=(3,3),\n",
    "                  input_shape=(image_size, image_size, 1)))\n",
    "model1.add(Conv2D(filters=1, kernel_size=kernel_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a different model structure, we will have a different number of weights to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 0.4344513 , -0.19506282]],\n",
       " \n",
       "         [[-0.09479725, -0.06614795]],\n",
       " \n",
       "         [[ 0.28828028, -0.3094995 ]]],\n",
       " \n",
       " \n",
       "        [[[-0.00374523, -0.07629231]],\n",
       " \n",
       "         [[ 0.40387586, -0.40334433]],\n",
       " \n",
       "         [[ 0.10026452, -0.41223776]]],\n",
       " \n",
       " \n",
       "        [[[-0.12125355, -0.14199588]],\n",
       " \n",
       "         [[ 0.37857804,  0.25269708]],\n",
       " \n",
       "         [[-0.30900228, -0.45309976]]]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[[[-0.42781356],\n",
       "          [ 0.4037414 ]],\n",
       " \n",
       "         [[ 0.29315755],\n",
       "          [ 0.03833094]],\n",
       " \n",
       "         [[ 0.33229294],\n",
       "          [ 0.19515213]]],\n",
       " \n",
       " \n",
       "        [[[-0.07263398],\n",
       "          [ 0.15618542]],\n",
       " \n",
       "         [[-0.01705194],\n",
       "          [-0.33214933]],\n",
       " \n",
       "         [[ 0.05809614],\n",
       "          [ 0.09155443]]],\n",
       " \n",
       " \n",
       "        [[[-0.4504543 ],\n",
       "          [ 0.27375063]],\n",
       " \n",
       "         [[-0.27375448],\n",
       "          [-0.4586427 ]],\n",
       " \n",
       "         [[ 0.13217512],\n",
       "          [-0.05921024]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we manually set the weights to match some specific patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_num = 0\n",
    "filter_num = 0\n",
    "for y in range(kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        if y == x:\n",
    "            weights[layer_num][y][x][0][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][0][filter_num] = -1\n",
    "\n",
    "filter_num = 1\n",
    "for y in range(kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        if kernel_size - 1 - y == x:\n",
    "            weights[layer_num][y][x][0][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][0][filter_num] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 1., -1.]],\n",
       " \n",
       "         [[-1., -1.]],\n",
       " \n",
       "         [[-1.,  1.]]],\n",
       " \n",
       " \n",
       "        [[[-1., -1.]],\n",
       " \n",
       "         [[ 1.,  1.]],\n",
       " \n",
       "         [[-1., -1.]]],\n",
       " \n",
       " \n",
       "        [[[-1.,  1.]],\n",
       " \n",
       "         [[-1., -1.]],\n",
       " \n",
       "         [[ 1., -1.]]]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[[[ 1.  ],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [ 1.  ]]],\n",
       " \n",
       " \n",
       "        [[[-0.25],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[ 1.  ],\n",
       "          [ 1.  ]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [-0.25]]],\n",
       " \n",
       " \n",
       "        [[[-0.25],\n",
       "          [ 1.  ]],\n",
       " \n",
       "         [[-0.25],\n",
       "          [-0.25]],\n",
       " \n",
       "         [[ 1.  ],\n",
       "          [-0.25]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_num = 2\n",
    "filter_num = 0\n",
    "for y in range(kernel_size):\n",
    "    for x in range(kernel_size):\n",
    "        input_filter_num = 0\n",
    "        if y == x:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = -0.25\n",
    "        input_filter_num = 1\n",
    "        if kernel_size - 1 - y == x:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = 1\n",
    "        else:\n",
    "            weights[layer_num][y][x][input_filter_num][filter_num] = -0.25\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save the weights back into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.set_weights(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, run our test images through the model to see what the filters output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_images(images):\n",
    "    resized_images = []\n",
    "    for image in images:\n",
    "        resized_images.append(numpy.resize(image, (image_size, image_size, 1)))\n",
    "    return model1.predict(numpy.array(resized_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-1150.]]],\n",
       "\n",
       "\n",
       "       [[[-1150.]]]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_images([image0, image1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Note above that neither image0 nor image1 gets a positive output. Create some images that do get positive ouputs from this model. The code below might help you get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12a6430b8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_black = numpy.array([\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image_black, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12a719080>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_white = numpy.array([\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "    [255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(image_white, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[    0.]]],\n",
       "\n",
       "\n",
       "       [[[-2295.]]]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_images([image_black, image_white])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[3315.]]]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = numpy.array([\n",
    "    [255,   0,   0, 255,   0, 255,   0,   0, 255],\n",
    "    [  0, 255,   0,   0, 255,   0,   0, 255,   0],\n",
    "    [  0,   0, 255,   0,   0,   0, 255,   0,   0],\n",
    "    [255,   0,   0, 255,   0, 255,   0,   0, 255],\n",
    "    [  0, 255,   0,   0, 255,   0,   0, 255,   0],\n",
    "    [  0,   0, 255,   0,   0,   0, 255,   0,   0],\n",
    "    [  0,   0, 255,   0,   0,   0, 255,   0,   0],\n",
    "    [  0, 255,   0,   0, 255,   0,   0, 255,   0],\n",
    "    [255,   0,   0, 255,   0, 255,   0,   0, 255],\n",
    "], dtype=numpy.uint8)\n",
    "imshow(test, cmap='gray', vmin=0, vmax=255)\n",
    "predict_images([test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 (Optional)\n",
    "\n",
    "Add additional filters to the model, and create images that get positive weights for different patterns of filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(filters=2,\n",
    "                  kernel_size=4,\n",
    "                  strides=(4,4),\n",
    "                  input_shape=(8, 8, 1)))\n",
    "model2.add(Conv2D(filters=1,\n",
    "                  kernel_size=2,\n",
    "                  strides=(2,2),\n",
    "                  input_shape=(4, 4, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 0.22711232,  0.03075987]],\n",
       " \n",
       "         [[-0.3326906 ,  0.2590964 ]],\n",
       " \n",
       "         [[-0.01308104,  0.24346879]],\n",
       " \n",
       "         [[-0.28553942, -0.10530247]]],\n",
       " \n",
       " \n",
       "        [[[ 0.22481641, -0.11413282]],\n",
       " \n",
       "         [[-0.20918484, -0.21272753]],\n",
       " \n",
       "         [[ 0.23806944, -0.20595318]],\n",
       " \n",
       "         [[-0.2441856 , -0.10393184]]],\n",
       " \n",
       " \n",
       "        [[[ 0.27593145,  0.12453854]],\n",
       " \n",
       "         [[ 0.21523628, -0.27619672]],\n",
       " \n",
       "         [[ 0.12900281, -0.04370359]],\n",
       " \n",
       "         [[-0.01062462, -0.15755023]]],\n",
       " \n",
       " \n",
       "        [[[ 0.26725462, -0.21777816]],\n",
       " \n",
       "         [[-0.00682154,  0.02701682]],\n",
       " \n",
       "         [[ 0.0282104 , -0.17059502]],\n",
       " \n",
       "         [[-0.134658  ,  0.33525136]]]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[[[ 0.6073707 ],\n",
       "          [-0.45647684]],\n",
       " \n",
       "         [[ 0.3254165 ],\n",
       "          [ 0.35955268]]],\n",
       " \n",
       " \n",
       "        [[[ 0.5956245 ],\n",
       "          [ 0.48994952]],\n",
       " \n",
       "         [[ 0.03951383],\n",
       "          [-0.48835164]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model2.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 1.,  1.]],\n",
       " \n",
       "         [[-1.,  1.]],\n",
       " \n",
       "         [[ 1., -1.]],\n",
       " \n",
       "         [[-1., -1.]]],\n",
       " \n",
       " \n",
       "        [[[-1.,  1.]],\n",
       " \n",
       "         [[ 1.,  1.]],\n",
       " \n",
       "         [[-1., -1.]],\n",
       " \n",
       "         [[ 1., -1.]]],\n",
       " \n",
       " \n",
       "        [[[ 1., -1.]],\n",
       " \n",
       "         [[-1., -1.]],\n",
       " \n",
       "         [[ 1.,  1.]],\n",
       " \n",
       "         [[-1.,  1.]]],\n",
       " \n",
       " \n",
       "        [[[-1., -1.]],\n",
       " \n",
       "         [[ 1., -1.]],\n",
       " \n",
       "         [[-1.,  1.]],\n",
       " \n",
       "         [[ 1.,  1.]]]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[[[ 1.],\n",
       "          [ 1.]],\n",
       " \n",
       "         [[-1.],\n",
       "          [ 1.]]],\n",
       " \n",
       " \n",
       "        [[[-1.],\n",
       "          [ 1.]],\n",
       " \n",
       "         [[ 1.],\n",
       "          [ 1.]]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights[0][0][0][0]\n",
    "\n",
    "for y in range(4):\n",
    "    for x in range(4):\n",
    "        if (y%2 == x%2):\n",
    "            weights[0][x][y][0][0] = 1\n",
    "        else:\n",
    "            weights[0][x][y][0][0] = -1\n",
    "\n",
    "for y in range(4):\n",
    "    for x in range(4):\n",
    "        if (math.floor((y/2)%2) == math.floor(x/2)%2):\n",
    "            weights[0][x][y][0][1] = 1\n",
    "        else:\n",
    "            weights[0][x][y][0][1] = -1\n",
    "            \n",
    "for y in range(2):\n",
    "    for x in range(2):\n",
    "        if (y%2 == x%2):\n",
    "            weights[2][x][y][0][0] = 1\n",
    "        else:\n",
    "            weights[2][x][y][0][0] = -1\n",
    "\n",
    "for y in range(2):\n",
    "    for x in range(2):\n",
    "        weights[2][x][y][1][0] = 1\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12b4e2710>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image3 = numpy.array([[0]*8]*8,dtype=numpy.uint8)\n",
    "for y in range(8):\n",
    "    for x in range(8):\n",
    "        image3[y][x] = random.random()*255\n",
    "imshow(image3, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_4_input to have 4 dimensions, but got array with shape (8, 8, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-6c6aa92011af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# created a new model that vaguely looks for checkered areas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimage3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              'argument.')\n\u001b[1;32m   1148\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_4_input to have 4 dimensions, but got array with shape (8, 8, 1)"
     ]
    }
   ],
   "source": [
    "# still getting this part to work\n",
    "# created a new model that vaguely looks for checkered areas but am yet to test it\n",
    "image3 = numpy.resize(image3, (8, 8, 1))\n",
    "model2.predict(image3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
