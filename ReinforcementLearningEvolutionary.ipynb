{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original code taken from [https://gist.github.com/EderSantana/c7222daa328f0e885093](https://gist.github.com/EderSantana/c7222daa328f0e885093)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "To be able to run the animation below, make sure you have the latest version of matplotlib, by running `pip3 install matplotlib --upgrade`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import sgd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import IPython.display\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the game environment and replay classes\n",
    "The idea in this Catch game is that there is fruit falling, and the user gets to move a basket so that they catch the fruit. If they catch it, they win and the game is over. If they miss it, they lose and the game is over. We are trying to teach the computer to play this game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Catch(object):\n",
    "    def __init__(self, grid_size=10):\n",
    "        '''        \n",
    "        Initializes internal state.\n",
    "        '''\n",
    "        self.grid_size = grid_size\n",
    "        self.min_basket_center = 1\n",
    "        self.max_basket_center = self.grid_size-2\n",
    "        self.reset()\n",
    "\n",
    "    def _update_state(self, action):\n",
    "        '''\n",
    "        Input: action (0 for left, 1 for stay, 2 for right)\n",
    "        \n",
    "        Moves basket according to action. Moves fruit down. Updates state to reflect these movements\n",
    "        '''\n",
    "        if action == 0:  # left\n",
    "            movement = -1\n",
    "        elif action == 1:  # stay\n",
    "            movement = 0\n",
    "        elif action == 2: # right\n",
    "            movement = 1\n",
    "        else:\n",
    "            raise Exception('Invalid action {}'.format(action))\n",
    "        fruit_x, fruit_y, basket_center = self.state\n",
    "        # move the basket unless this would move it off the edge of the grid\n",
    "        new_basket_center = min(max(self.min_basket_center, basket_center + movement), self.max_basket_center)\n",
    "        # move fruit down\n",
    "        fruit_y += 1\n",
    "        out = np.asarray([fruit_x, fruit_y, new_basket_center])\n",
    "        self.state = out\n",
    "\n",
    "    def _draw_state(self):\n",
    "        '''\n",
    "        Returns a 2D numpy array with 1s (white squares) at the locations of the fruit and basket and\n",
    "        0s (black squares) everywhere else.\n",
    "        '''\n",
    "        im_size = (self.grid_size, self.grid_size)\n",
    "        canvas = np.zeros(im_size)\n",
    "        \n",
    "        fruit_x, fruit_y, basket_center = self.state\n",
    "        canvas[fruit_y, fruit_x] = 1  # draw fruit\n",
    "        canvas[-1, basket_center-1:basket_center + 2] = 1  # draw 3-pixel basket\n",
    "        return canvas\n",
    "\n",
    "    def _get_reward(self):\n",
    "        '''\n",
    "        Returns 1 if the fruit was caught, -1 if it was dropped, and 0 if it is still in the air.\n",
    "        '''\n",
    "        fruit_x, fruit_y, basket_center = self.state\n",
    "        if fruit_y == self.grid_size-1:\n",
    "            if abs(fruit_x - basket_center) <= 1:\n",
    "                return 1 # it caught the fruit\n",
    "            else:\n",
    "                return -1 # it dropped the fruit\n",
    "        else:\n",
    "            return 0 # the fruit is still in the air\n",
    "\n",
    "    def observe(self):\n",
    "        '''\n",
    "        Returns the current canvas, as a 1D array.\n",
    "        '''\n",
    "        canvas = self._draw_state()\n",
    "        return canvas.reshape((1, -1))\n",
    "\n",
    "    def act(self, policy):\n",
    "        '''\n",
    "        Input: policy (a 10x10x10 array of actions for each possible state of fruit_x, fruit_y, and basket_center\n",
    "        with 0 for left, 1 for stay, 2 for right)\n",
    "        \n",
    "        Returns:\n",
    "            current canvas (as a 1D array)\n",
    "            reward received after this action\n",
    "            True if game is over and False otherwise\n",
    "        '''\n",
    "        fruit_x, fruit_y, basket_center = self.state\n",
    "        action = policy[fruit_x][fruit_y][basket_center]\n",
    "        if (action not in [0,1,2]):\n",
    "            print(\"BAD\")\n",
    "#             print(policy)\n",
    "#         print(\"Policy:\")\n",
    "#         print(policy)\n",
    "#         print(\"Action:\")\n",
    "#         print(action)\n",
    "        self._update_state(action)\n",
    "        observation = self.observe()\n",
    "        reward = self._get_reward()\n",
    "        game_over = (reward != 0) # if the reward is zero, the fruit is still in the air\n",
    "        return observation, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        '''\n",
    "        Updates internal state\n",
    "            fruit in a random column in the top row\n",
    "            basket center in a random column\n",
    "        '''\n",
    "        fruit_x = random.randint(0, self.grid_size-1)\n",
    "        fruit_y = 0\n",
    "        basket_center = random.randint(self.min_basket_center, self.max_basket_center)\n",
    "        self.state = np.asarray([fruit_x, fruit_y, basket_center])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperienceReplay(object):\n",
    "    def __init__(self, max_memory=100, discount=.9):\n",
    "        self.max_memory = max_memory\n",
    "        self.memory = list()\n",
    "        self.discount = discount\n",
    "\n",
    "    def remember(self, states, game_over):\n",
    "        '''\n",
    "        Input:\n",
    "            states: [starting_observation, action_taken, reward_received, new_observation]\n",
    "            game_over: boolean\n",
    "        Add the states and game over to the internal memory array. If the array is longer than\n",
    "        self.max_memory, drop the oldest memory\n",
    "        '''\n",
    "        self.memory.append([states, game_over])\n",
    "        if len(self.memory) > self.max_memory:\n",
    "            del self.memory[0]\n",
    "\n",
    "    def get_batch(self, model, batch_size=10):\n",
    "        '''\n",
    "        Randomly chooses batch_size memories, possibly repeating.\n",
    "        For each of these memories, updates the models current best guesses about the value of taking a\n",
    "            certain action from the starting state, based on the reward received and the model's current\n",
    "            estimate of how valuable the new state is.\n",
    "        '''\n",
    "        len_memory = len(self.memory)\n",
    "        num_actions = model.output_shape[-1] # the number of possible actions\n",
    "        env_dim = self.memory[0][0][0].shape[1] # the number of pixels in the image\n",
    "        input_size = min(len_memory, batch_size)\n",
    "        inputs = np.zeros((input_size, env_dim))\n",
    "        targets = np.zeros((input_size, num_actions))\n",
    "        for i, idx in enumerate(np.random.randint(0, len_memory, size=input_size)):\n",
    "            starting_observation, action_taken, reward_received, new_observation = self.memory[idx][0]\n",
    "            game_over = self.memory[idx][1]\n",
    "\n",
    "            # Set the input to the state that was observed in the game before an action was taken\n",
    "            inputs[i:i+1] = starting_observation\n",
    "            \n",
    "            # Start with the model's current best guesses about the value of taking each action from this state\n",
    "            targets[i] = model.predict(starting_observation)[0]\n",
    "            \n",
    "            # Now we need to update the value of the action that was taken                      \n",
    "            if game_over: \n",
    "                # if the game is over, give the actual reward received\n",
    "                targets[i, action_taken] = reward_received\n",
    "            else:\n",
    "                # if the game is not over, give the reward received (always zero in this particular game)\n",
    "                # plus the maximum reward predicted for state we got to by taking this action (with a discount)\n",
    "                Q_sa = np.max(model.predict(new_observation)[0])\n",
    "                targets[i, action_taken] = reward_received + self.discount * Q_sa\n",
    "        return inputs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Functions for creating, training, and visualizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "epsilon = .1  # probability of exploration (choosing a random action instead of the current best one)\n",
    "num_actions = 3  # [move_left, stay, move_right]\n",
    "max_memory = 500\n",
    "hidden_size = 100\n",
    "batch_size = 50\n",
    "grid_size = 10\n",
    "\n",
    "def run_episode(env, policy, exp_replay, grid_size=10, episode_len=100):\n",
    "    total_reward = 0\n",
    "    obs = env.reset()\n",
    "    for t in range(episode_len):\n",
    "        fruit_x, fruit_y, basket_center = env.state\n",
    "        obs, reward, done = env.act(policy)\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            # store experience\n",
    "            exp_replay.remember([starting_observation, action, reward, new_observation], game_over)\n",
    "\n",
    "            # get data updated based on the stored experiences\n",
    "            inputs, targets = exp_replay.get_batch(model, batch_size=batch_size)\n",
    "\n",
    "            # train model on the updated data\n",
    "            loss += model.train_on_batch(inputs, targets)\n",
    "\n",
    "            starting_observation = new_observation # for next time through the loop\n",
    "            # print('Episode finished after {} timesteps.'.format(t+1))\n",
    "            break\n",
    "    return total_reward\n",
    "\n",
    "def evaluate_policy(env, policy, exp_replay, n_episodes=100):\n",
    "    total_rewards = 0.0\n",
    "    for _ in range(n_episodes):\n",
    "        total_rewards += run_episode(env, policy, exp_replay)\n",
    "    return total_rewards / n_episodes\n",
    "\n",
    "def gen_random_policy():\n",
    "    return np.random.choice(3, size=((10,10,10)))\n",
    "\n",
    "def crossover(policy1, policy2, grid_size=10):\n",
    "    new_policy = policy1.copy()\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            for k in range(10):\n",
    "                rand = np.random.uniform()\n",
    "                if rand > 0.5:\n",
    "                    new_policy[i][j][k] = policy2[i][j][k]\n",
    "    return new_policy\n",
    "\n",
    "def mutation(policy, p=0.05):\n",
    "    new_policy = policy.copy()\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            for k in range(10):\n",
    "                rand = np.random.uniform()\n",
    "                if rand < p:\n",
    "                    new_policy[i] = np.random.choice(3)\n",
    "    return new_policy\n",
    "\n",
    "def build_model():\n",
    "    '''\n",
    "     Returns three initialized objects: the model, the environment, and the replay.\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_size, input_shape=(grid_size**2,), activation='relu'))\n",
    "    model.add(Dense(hidden_size, activation='relu'))\n",
    "    model.add(Dense(num_actions))\n",
    "    model.compile(sgd(lr=.2), \"mse\")\n",
    "\n",
    "    # Define environment/game\n",
    "    env = Catch()\n",
    "\n",
    "    # Initialize experience replay object\n",
    "    exp_replay = ExperienceReplay(max_memory=max_memory)\n",
    "    \n",
    "    return model, env, exp_replay\n",
    "\n",
    "def create_animation(model, env, num_games):\n",
    "    '''\n",
    "    Inputs:\n",
    "        model and env objects as returned from build_model\n",
    "        num_games: integer, the number of games to be included in the animation\n",
    "        \n",
    "    Returns: a matplotlib animation object\n",
    "    '''\n",
    "    # Animation code from \n",
    "    # https://matplotlib.org/examples/animation/dynamic_image.html\n",
    "    # https://stackoverflow.com/questions/35532498/animation-in-ipython-notebook/46878531#46878531\n",
    "    \n",
    "    # First, play the games and collect all of the images for each observed state\n",
    "    observations = []\n",
    "    for _ in range(num_games):\n",
    "        env.reset()\n",
    "        observation = env.observe()\n",
    "        observations.append(observation)\n",
    "        game_over = False\n",
    "        while game_over == False:\n",
    "            q = model.predict(observation)\n",
    "            policy = np.argmax(q[0])\n",
    "            \n",
    "            # apply action, get rewards and new state\n",
    "            observation, reward, game_over = env.act(policy)\n",
    "            observations.append(observation)\n",
    "            \n",
    "    fig = plt.figure()\n",
    "    image = plt.imshow(np.zeros((grid_size, grid_size)),interpolation='none', cmap='gray', animated=True, vmin=0, vmax=1)\n",
    "    \n",
    "    def animate(observation):\n",
    "        image.set_array(observation.reshape((grid_size, grid_size)))\n",
    "        return [image]\n",
    "   \n",
    "    animation = matplotlib.animation.FuncAnimation(fig, animate, frames=observations, blit=True, )\n",
    "    return animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 : max score = 0.08\n",
      "Generation 2 : max score = 0.26\n",
      "Generation 3 : max score = 0.30\n",
      "Generation 4 : max score = 0.40\n",
      "Generation 5 : max score = 0.28\n",
      "Generation 6 : max score = 0.38\n",
      "Generation 7 : max score = 0.36\n",
      "Generation 8 : max score = 0.38\n",
      "Generation 9 : max score = 0.34\n",
      "Generation 10 : max score = 0.38\n",
      "Generation 11 : max score = 0.30\n",
      "Generation 12 : max score = 0.34\n",
      "Generation 13 : max score = 0.40\n",
      "Generation 14 : max score = 0.28\n",
      "Generation 15 : max score = 0.28\n",
      "Generation 16 : max score = 0.30\n",
      "Generation 17 : max score = 0.36\n",
      "Generation 18 : max score = 0.38\n",
      "Generation 19 : max score = 0.44\n",
      "Generation 20 : max score = 0.44\n",
      "Generation 21 : max score = 0.34\n",
      "Generation 22 : max score = 0.44\n",
      "Generation 23 : max score = 0.40\n",
      "Generation 24 : max score = 0.40\n",
      "Generation 25 : max score = 0.32\n",
      "Generation 26 : max score = 0.36\n",
      "Generation 27 : max score = 0.40\n",
      "Generation 28 : max score = 0.40\n",
      "Generation 29 : max score = 0.32\n",
      "Generation 30 : max score = 0.38\n",
      "Generation 31 : max score = 0.38\n",
      "Generation 32 : max score = 0.38\n",
      "Generation 33 : max score = 0.34\n",
      "Generation 34 : max score = 0.40\n",
      "Generation 35 : max score = 0.38\n",
      "Generation 36 : max score = 0.34\n",
      "Generation 37 : max score = 0.32\n",
      "Generation 38 : max score = 0.38\n",
      "Generation 39 : max score = 0.54\n",
      "Generation 40 : max score = 0.42\n",
      "Generation 41 : max score = 0.56\n",
      "Generation 42 : max score = 0.42\n",
      "Generation 43 : max score = 0.44\n",
      "Generation 44 : max score = 0.32\n",
      "Generation 45 : max score = 0.56\n",
      "Generation 46 : max score = 0.54\n",
      "Generation 47 : max score = 0.42\n",
      "Generation 48 : max score = 0.60\n",
      "Generation 49 : max score = 0.46\n",
      "Generation 50 : max score = 0.44\n",
      "Generation 51 : max score = 0.50\n",
      "Generation 52 : max score = 0.48\n",
      "Generation 53 : max score = 0.34\n",
      "Generation 54 : max score = 0.50\n",
      "Generation 55 : max score = 0.38\n",
      "Generation 56 : max score = 0.44\n",
      "Generation 57 : max score = 0.60\n",
      "Generation 58 : max score = 0.58\n",
      "Generation 59 : max score = 0.40\n",
      "Generation 60 : max score = 0.38\n",
      "Generation 61 : max score = 0.42\n",
      "Generation 62 : max score = 0.46\n",
      "Generation 63 : max score = 0.42\n",
      "Generation 64 : max score = 0.42\n",
      "Generation 65 : max score = 0.58\n",
      "Generation 66 : max score = 0.46\n",
      "Generation 67 : max score = 0.46\n",
      "Generation 68 : max score = 0.58\n",
      "Generation 69 : max score = 0.46\n",
      "Generation 70 : max score = 0.42\n",
      "Generation 71 : max score = 0.52\n",
      "Generation 72 : max score = 0.48\n",
      "Generation 73 : max score = 0.52\n",
      "Generation 74 : max score = 0.42\n",
      "Generation 75 : max score = 0.40\n",
      "Generation 76 : max score = 0.38\n",
      "Generation 77 : max score = 0.34\n",
      "Generation 78 : max score = 0.38\n",
      "Generation 79 : max score = 0.44\n",
      "Generation 80 : max score = 0.32\n",
      "Generation 81 : max score = 0.44\n",
      "Generation 82 : max score = 0.40\n",
      "Generation 83 : max score = 0.34\n",
      "Generation 84 : max score = 0.34\n",
      "Generation 85 : max score = 0.30\n",
      "Generation 86 : max score = 0.40\n",
      "Generation 87 : max score = 0.48\n",
      "Generation 88 : max score = 0.32\n",
      "Generation 89 : max score = 0.46\n",
      "Generation 90 : max score = 0.54\n",
      "Generation 91 : max score = 0.44\n",
      "Generation 92 : max score = 0.36\n",
      "Generation 93 : max score = 0.44\n",
      "Generation 94 : max score = 0.52\n",
      "Generation 95 : max score = 0.38\n",
      "Generation 96 : max score = 0.44\n",
      "Generation 97 : max score = 0.42\n",
      "Generation 98 : max score = 0.44\n",
      "Generation 99 : max score = 0.40\n",
      "Generation 100 : max score = 0.48\n",
      "Generation 101 : max score = 0.42\n",
      "Generation 102 : max score = 0.42\n",
      "Generation 103 : max score = 0.38\n",
      "Generation 104 : max score = 0.48\n",
      "Generation 105 : max score = 0.46\n",
      "Generation 106 : max score = 0.56\n",
      "Generation 107 : max score = 0.46\n",
      "Generation 108 : max score = 0.38\n",
      "Generation 109 : max score = 0.44\n",
      "Generation 110 : max score = 0.48\n",
      "Generation 111 : max score = 0.42\n",
      "Generation 112 : max score = 0.40\n",
      "Generation 113 : max score = 0.40\n",
      "Generation 114 : max score = 0.48\n",
      "Generation 115 : max score = 0.44\n",
      "Generation 116 : max score = 0.38\n",
      "Generation 117 : max score = 0.42\n",
      "Generation 118 : max score = 0.50\n",
      "Generation 119 : max score = 0.42\n",
      "Generation 120 : max score = 0.44\n",
      "Generation 121 : max score = 0.44\n",
      "Generation 122 : max score = 0.36\n",
      "Generation 123 : max score = 0.52\n",
      "Generation 124 : max score = 0.36\n",
      "Generation 125 : max score = 0.46\n",
      "Generation 126 : max score = 0.52\n",
      "Generation 127 : max score = 0.42\n",
      "Generation 128 : max score = 0.42\n",
      "Generation 129 : max score = 0.50\n",
      "Generation 130 : max score = 0.44\n",
      "Generation 131 : max score = 0.44\n",
      "Generation 132 : max score = 0.52\n",
      "Generation 133 : max score = 0.44\n",
      "Generation 134 : max score = 0.46\n",
      "Generation 135 : max score = 0.46\n",
      "Generation 136 : max score = 0.46\n",
      "Generation 137 : max score = 0.42\n",
      "Generation 138 : max score = 0.56\n",
      "Generation 139 : max score = 0.40\n",
      "Generation 140 : max score = 0.44\n",
      "Generation 141 : max score = 0.38\n",
      "Generation 142 : max score = 0.34\n",
      "Generation 143 : max score = 0.38\n",
      "Generation 144 : max score = 0.38\n",
      "Generation 145 : max score = 0.38\n",
      "Generation 146 : max score = 0.46\n",
      "Generation 147 : max score = 0.44\n",
      "Generation 148 : max score = 0.36\n",
      "Generation 149 : max score = 0.42\n",
      "Generation 150 : max score = 0.38\n",
      "Generation 151 : max score = 0.36\n",
      "Generation 152 : max score = 0.40\n",
      "Generation 153 : max score = 0.44\n",
      "Generation 154 : max score = 0.42\n",
      "Generation 155 : max score = 0.42\n",
      "Generation 156 : max score = 0.40\n",
      "Generation 157 : max score = 0.36\n",
      "Generation 158 : max score = 0.38\n",
      "Generation 159 : max score = 0.46\n",
      "Generation 160 : max score = 0.38\n",
      "Generation 161 : max score = 0.38\n",
      "Generation 162 : max score = 0.42\n",
      "Generation 163 : max score = 0.32\n",
      "Generation 164 : max score = 0.36\n",
      "Generation 165 : max score = 0.38\n",
      "Generation 166 : max score = 0.36\n",
      "Generation 167 : max score = 0.26\n",
      "Generation 168 : max score = 0.44\n",
      "Generation 169 : max score = 0.42\n",
      "Generation 170 : max score = 0.36\n",
      "Generation 171 : max score = 0.48\n",
      "Generation 172 : max score = 0.38\n",
      "Generation 173 : max score = 0.32\n",
      "Generation 174 : max score = 0.38\n",
      "Generation 175 : max score = 0.36\n",
      "Generation 176 : max score = 0.36\n",
      "Generation 177 : max score = 0.24\n",
      "Generation 178 : max score = 0.28\n",
      "Generation 179 : max score = 0.42\n",
      "Generation 180 : max score = 0.32\n",
      "Generation 181 : max score = 0.26\n",
      "Generation 182 : max score = 0.38\n",
      "Generation 183 : max score = 0.26\n",
      "Generation 184 : max score = 0.42\n",
      "Generation 185 : max score = 0.50\n",
      "Generation 186 : max score = 0.38\n",
      "Generation 187 : max score = 0.38\n",
      "Generation 188 : max score = 0.32\n",
      "Generation 189 : max score = 0.38\n",
      "Generation 190 : max score = 0.34\n",
      "Generation 191 : max score = 0.34\n",
      "Generation 192 : max score = 0.42\n",
      "Generation 193 : max score = 0.42\n",
      "Generation 194 : max score = 0.32\n",
      "Generation 195 : max score = 0.40\n",
      "Generation 196 : max score = 0.42\n",
      "Generation 197 : max score = 0.48\n",
      "Generation 198 : max score = 0.40\n",
      "Generation 199 : max score = 0.38\n",
      "Generation 200 : max score = 0.50\n",
      "Generation 201 : max score = 0.38\n",
      "Generation 202 : max score = 0.46\n",
      "Generation 203 : max score = 0.56\n",
      "Generation 204 : max score = 0.48\n",
      "Generation 205 : max score = 0.64\n",
      "Generation 206 : max score = 0.50\n",
      "Generation 207 : max score = 0.46\n",
      "Generation 208 : max score = 0.38\n",
      "Generation 209 : max score = 0.52\n",
      "Generation 210 : max score = 0.48\n",
      "Generation 211 : max score = 0.46\n",
      "Generation 212 : max score = 0.54\n",
      "Generation 213 : max score = 0.46\n",
      "Generation 214 : max score = 0.38\n",
      "Generation 215 : max score = 0.44\n",
      "Generation 216 : max score = 0.50\n",
      "Generation 217 : max score = 0.46\n",
      "Generation 218 : max score = 0.54\n",
      "Generation 219 : max score = 0.56\n",
      "Generation 220 : max score = 0.58\n",
      "Generation 221 : max score = 0.68\n",
      "Generation 222 : max score = 0.44\n",
      "Generation 223 : max score = 0.40\n",
      "Generation 224 : max score = 0.40\n",
      "Generation 225 : max score = 0.54\n",
      "Generation 226 : max score = 0.44\n",
      "Generation 227 : max score = 0.50\n",
      "Generation 228 : max score = 0.54\n",
      "Generation 229 : max score = 0.38\n",
      "Generation 230 : max score = 0.54\n",
      "Generation 231 : max score = 0.44\n",
      "Generation 232 : max score = 0.42\n",
      "Generation 233 : max score = 0.44\n",
      "Generation 234 : max score = 0.34\n",
      "Generation 235 : max score = 0.36\n",
      "Generation 236 : max score = 0.56\n",
      "Generation 237 : max score = 0.60\n",
      "Generation 238 : max score = 0.46\n",
      "Generation 239 : max score = 0.42\n",
      "Generation 240 : max score = 0.30\n",
      "Generation 241 : max score = 0.42\n",
      "Generation 242 : max score = 0.42\n",
      "Generation 243 : max score = 0.34\n",
      "Generation 244 : max score = 0.46\n",
      "Generation 245 : max score = 0.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 246 : max score = 0.48\n",
      "Generation 247 : max score = 0.56\n",
      "Generation 248 : max score = 0.46\n",
      "Generation 249 : max score = 0.36\n",
      "Generation 250 : max score = 0.50\n",
      "Generation 251 : max score = 0.44\n",
      "Generation 252 : max score = 0.42\n",
      "Generation 253 : max score = 0.40\n",
      "Generation 254 : max score = 0.44\n",
      "Generation 255 : max score = 0.44\n",
      "Generation 256 : max score = 0.56\n",
      "Generation 257 : max score = 0.50\n",
      "Generation 258 : max score = 0.50\n",
      "Generation 259 : max score = 0.42\n",
      "Generation 260 : max score = 0.42\n",
      "Generation 261 : max score = 0.52\n",
      "Generation 262 : max score = 0.50\n",
      "Generation 263 : max score = 0.42\n",
      "Generation 264 : max score = 0.40\n",
      "Generation 265 : max score = 0.58\n",
      "Generation 266 : max score = 0.38\n",
      "Generation 267 : max score = 0.48\n",
      "Generation 268 : max score = 0.48\n",
      "Generation 269 : max score = 0.40\n",
      "Generation 270 : max score = 0.52\n",
      "Generation 271 : max score = 0.50\n",
      "Generation 272 : max score = 0.56\n",
      "Generation 273 : max score = 0.48\n",
      "Generation 274 : max score = 0.36\n",
      "Generation 275 : max score = 0.56\n",
      "Generation 276 : max score = 0.50\n",
      "Generation 277 : max score = 0.54\n",
      "Generation 278 : max score = 0.46\n",
      "Generation 279 : max score = 0.34\n",
      "Generation 280 : max score = 0.44\n",
      "Generation 281 : max score = 0.36\n",
      "Generation 282 : max score = 0.36\n",
      "Generation 283 : max score = 0.38\n",
      "Generation 284 : max score = 0.48\n",
      "Generation 285 : max score = 0.34\n",
      "Generation 286 : max score = 0.48\n",
      "Generation 287 : max score = 0.32\n",
      "Generation 288 : max score = 0.38\n",
      "Generation 289 : max score = 0.44\n",
      "Generation 290 : max score = 0.48\n",
      "Generation 291 : max score = 0.48\n",
      "Generation 292 : max score = 0.42\n",
      "Generation 293 : max score = 0.42\n",
      "Generation 294 : max score = 0.46\n",
      "Generation 295 : max score = 0.42\n",
      "Generation 296 : max score = 0.44\n",
      "Generation 297 : max score = 0.54\n",
      "Generation 298 : max score = 0.44\n",
      "Generation 299 : max score = 0.36\n",
      "Generation 300 : max score = 0.46\n",
      "Generation 301 : max score = 0.36\n",
      "Generation 302 : max score = 0.46\n",
      "Generation 303 : max score = 0.50\n",
      "Generation 304 : max score = 0.44\n",
      "Generation 305 : max score = 0.42\n",
      "Generation 306 : max score = 0.50\n",
      "Generation 307 : max score = 0.60\n",
      "Generation 308 : max score = 0.44\n",
      "Generation 309 : max score = 0.38\n",
      "Generation 310 : max score = 0.50\n",
      "Generation 311 : max score = 0.34\n",
      "Generation 312 : max score = 0.40\n",
      "Generation 313 : max score = 0.40\n",
      "Generation 314 : max score = 0.56\n",
      "Generation 315 : max score = 0.52\n",
      "Generation 316 : max score = 0.42\n",
      "Generation 317 : max score = 0.38\n",
      "Generation 318 : max score = 0.54\n",
      "Generation 319 : max score = 0.40\n",
      "Generation 320 : max score = 0.58\n",
      "Generation 321 : max score = 0.38\n",
      "Generation 322 : max score = 0.54\n",
      "Generation 323 : max score = 0.44\n",
      "Generation 324 : max score = 0.44\n",
      "Generation 325 : max score = 0.58\n",
      "Generation 326 : max score = 0.46\n",
      "Generation 327 : max score = 0.54\n",
      "Generation 328 : max score = 0.38\n",
      "Generation 329 : max score = 0.52\n",
      "Generation 330 : max score = 0.48\n",
      "Generation 331 : max score = 0.52\n",
      "Generation 332 : max score = 0.44\n",
      "Generation 333 : max score = 0.54\n",
      "Generation 334 : max score = 0.56\n",
      "Generation 335 : max score = 0.58\n",
      "Generation 336 : max score = 0.54\n",
      "Generation 337 : max score = 0.54\n",
      "Generation 338 : max score = 0.64\n",
      "Generation 339 : max score = 0.56\n",
      "Generation 340 : max score = 0.48\n",
      "Generation 341 : max score = 0.58\n",
      "Generation 342 : max score = 0.50\n",
      "Generation 343 : max score = 0.50\n",
      "Generation 344 : max score = 0.62\n",
      "Generation 345 : max score = 0.56\n",
      "Generation 346 : max score = 0.48\n",
      "Generation 347 : max score = 0.56\n",
      "Generation 348 : max score = 0.62\n",
      "Generation 349 : max score = 0.48\n",
      "Generation 350 : max score = 0.54\n",
      "Generation 351 : max score = 0.54\n",
      "Generation 352 : max score = 0.48\n",
      "Generation 353 : max score = 0.54\n",
      "Generation 354 : max score = 0.60\n",
      "Generation 355 : max score = 0.48\n",
      "Generation 356 : max score = 0.54\n",
      "Generation 357 : max score = 0.44\n",
      "Generation 358 : max score = 0.48\n",
      "Generation 359 : max score = 0.50\n",
      "Generation 360 : max score = 0.58\n",
      "Generation 361 : max score = 0.50\n",
      "Generation 362 : max score = 0.64\n",
      "Generation 363 : max score = 0.62\n",
      "Generation 364 : max score = 0.64\n",
      "Generation 365 : max score = 0.52\n",
      "Generation 366 : max score = 0.54\n",
      "Generation 367 : max score = 0.62\n",
      "Generation 368 : max score = 0.58\n",
      "Generation 369 : max score = 0.48\n",
      "Generation 370 : max score = 0.48\n",
      "Generation 371 : max score = 0.54\n",
      "Generation 372 : max score = 0.54\n",
      "Generation 373 : max score = 0.78\n",
      "Generation 374 : max score = 0.54\n",
      "Generation 375 : max score = 0.68\n",
      "Generation 376 : max score = 0.50\n",
      "Generation 377 : max score = 0.52\n",
      "Generation 378 : max score = 0.52\n",
      "Generation 379 : max score = 0.46\n",
      "Generation 380 : max score = 0.56\n",
      "Generation 381 : max score = 0.50\n",
      "Generation 382 : max score = 0.58\n",
      "Generation 383 : max score = 0.58\n",
      "Generation 384 : max score = 0.58\n",
      "Generation 385 : max score = 0.58\n",
      "Generation 386 : max score = 0.62\n",
      "Generation 387 : max score = 0.48\n",
      "Generation 388 : max score = 0.48\n",
      "Generation 389 : max score = 0.56\n",
      "Generation 390 : max score = 0.62\n",
      "Generation 391 : max score = 0.62\n",
      "Generation 392 : max score = 0.54\n",
      "Generation 393 : max score = 0.64\n",
      "Generation 394 : max score = 0.64\n",
      "Generation 395 : max score = 0.48\n",
      "Generation 396 : max score = 0.62\n",
      "Generation 397 : max score = 0.58\n",
      "Generation 398 : max score = 0.52\n",
      "Generation 399 : max score = 0.54\n",
      "Generation 400 : max score = 0.60\n",
      "Generation 401 : max score = 0.50\n",
      "Generation 402 : max score = 0.60\n",
      "Generation 403 : max score = 0.64\n",
      "Generation 404 : max score = 0.48\n",
      "Generation 405 : max score = 0.50\n",
      "Generation 406 : max score = 0.46\n",
      "Generation 407 : max score = 0.58\n",
      "Generation 408 : max score = 0.46\n",
      "Generation 409 : max score = 0.56\n",
      "Generation 410 : max score = 0.54\n",
      "Generation 411 : max score = 0.52\n",
      "Generation 412 : max score = 0.58\n",
      "Generation 413 : max score = 0.60\n",
      "Generation 414 : max score = 0.60\n",
      "Generation 415 : max score = 0.46\n",
      "Generation 416 : max score = 0.50\n",
      "Generation 417 : max score = 0.52\n",
      "Generation 418 : max score = 0.54\n",
      "Generation 419 : max score = 0.60\n",
      "Generation 420 : max score = 0.50\n",
      "Generation 421 : max score = 0.48\n",
      "Generation 422 : max score = 0.58\n",
      "Generation 423 : max score = 0.64\n",
      "Generation 424 : max score = 0.54\n",
      "Generation 425 : max score = 0.58\n",
      "Generation 426 : max score = 0.52\n",
      "Generation 427 : max score = 0.60\n",
      "Generation 428 : max score = 0.68\n",
      "Generation 429 : max score = 0.62\n",
      "Generation 430 : max score = 0.52\n",
      "Generation 431 : max score = 0.64\n",
      "Generation 432 : max score = 0.50\n",
      "Generation 433 : max score = 0.64\n",
      "Generation 434 : max score = 0.56\n",
      "Generation 435 : max score = 0.66\n",
      "Generation 436 : max score = 0.40\n",
      "Generation 437 : max score = 0.58\n",
      "Generation 438 : max score = 0.60\n",
      "Generation 439 : max score = 0.48\n",
      "Generation 440 : max score = 0.58\n",
      "Generation 441 : max score = 0.60\n",
      "Generation 442 : max score = 0.70\n",
      "Generation 443 : max score = 0.58\n",
      "Generation 444 : max score = 0.52\n",
      "Generation 445 : max score = 0.50\n",
      "Generation 446 : max score = 0.52\n",
      "Generation 447 : max score = 0.50\n",
      "Generation 448 : max score = 0.60\n",
      "Generation 449 : max score = 0.60\n",
      "Generation 450 : max score = 0.58\n",
      "Generation 451 : max score = 0.44\n",
      "Generation 452 : max score = 0.56\n",
      "Generation 453 : max score = 0.62\n",
      "Generation 454 : max score = 0.56\n",
      "Generation 455 : max score = 0.54\n",
      "Generation 456 : max score = 0.66\n",
      "Generation 457 : max score = 0.56\n",
      "Generation 458 : max score = 0.62\n",
      "Generation 459 : max score = 0.50\n",
      "Generation 460 : max score = 0.60\n",
      "Generation 461 : max score = 0.68\n",
      "Generation 462 : max score = 0.54\n",
      "Generation 463 : max score = 0.52\n",
      "Generation 464 : max score = 0.62\n",
      "Generation 465 : max score = 0.66\n",
      "Generation 466 : max score = 0.50\n",
      "Generation 467 : max score = 0.52\n",
      "Generation 468 : max score = 0.66\n",
      "Generation 469 : max score = 0.54\n",
      "Generation 470 : max score = 0.54\n",
      "Generation 471 : max score = 0.64\n",
      "Generation 472 : max score = 0.54\n",
      "Generation 473 : max score = 0.56\n",
      "Generation 474 : max score = 0.46\n",
      "Generation 475 : max score = 0.60\n",
      "Generation 476 : max score = 0.50\n",
      "Generation 477 : max score = 0.64\n",
      "Generation 478 : max score = 0.58\n",
      "Generation 479 : max score = 0.50\n",
      "Generation 480 : max score = 0.48\n",
      "Generation 481 : max score = 0.64\n",
      "Generation 482 : max score = 0.54\n",
      "Generation 483 : max score = 0.54\n",
      "Generation 484 : max score = 0.56\n",
      "Generation 485 : max score = 0.52\n",
      "Generation 486 : max score = 0.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 487 : max score = 0.52\n",
      "Generation 488 : max score = 0.50\n",
      "Generation 489 : max score = 0.54\n",
      "Generation 490 : max score = 0.54\n",
      "Generation 491 : max score = 0.50\n",
      "Generation 492 : max score = 0.48\n",
      "Generation 493 : max score = 0.44\n",
      "Generation 494 : max score = 0.60\n",
      "Generation 495 : max score = 0.60\n",
      "Generation 496 : max score = 0.50\n",
      "Generation 497 : max score = 0.44\n",
      "Generation 498 : max score = 0.54\n",
      "Generation 499 : max score = 0.56\n",
      "Generation 500 : max score = 0.66\n",
      "Generation 501 : max score = 0.48\n",
      "Generation 502 : max score = 0.50\n",
      "Generation 503 : max score = 0.58\n",
      "Generation 504 : max score = 0.58\n",
      "Generation 505 : max score = 0.40\n",
      "Generation 506 : max score = 0.48\n",
      "Generation 507 : max score = 0.52\n",
      "Generation 508 : max score = 0.46\n",
      "Generation 509 : max score = 0.46\n",
      "Generation 510 : max score = 0.58\n",
      "Generation 511 : max score = 0.46\n",
      "Generation 512 : max score = 0.34\n",
      "Generation 513 : max score = 0.50\n",
      "Generation 514 : max score = 0.44\n",
      "Generation 515 : max score = 0.40\n",
      "Generation 516 : max score = 0.54\n",
      "Generation 517 : max score = 0.46\n",
      "Generation 518 : max score = 0.50\n",
      "Generation 519 : max score = 0.34\n",
      "Generation 520 : max score = 0.62\n",
      "Generation 521 : max score = 0.56\n",
      "Generation 522 : max score = 0.54\n",
      "Generation 523 : max score = 0.54\n",
      "Generation 524 : max score = 0.50\n",
      "Generation 525 : max score = 0.60\n",
      "Generation 526 : max score = 0.34\n",
      "Generation 527 : max score = 0.58\n",
      "Generation 528 : max score = 0.52\n",
      "Generation 529 : max score = 0.46\n",
      "Generation 530 : max score = 0.38\n",
      "Generation 531 : max score = 0.56\n",
      "Generation 532 : max score = 0.42\n",
      "Generation 533 : max score = 0.36\n",
      "Generation 534 : max score = 0.60\n",
      "Generation 535 : max score = 0.56\n",
      "Generation 536 : max score = 0.50\n",
      "Generation 537 : max score = 0.58\n",
      "Generation 538 : max score = 0.42\n",
      "Generation 539 : max score = 0.52\n",
      "Generation 540 : max score = 0.62\n",
      "Generation 541 : max score = 0.32\n",
      "Generation 542 : max score = 0.42\n",
      "Generation 543 : max score = 0.40\n",
      "Generation 544 : max score = 0.42\n",
      "Generation 545 : max score = 0.50\n",
      "Generation 546 : max score = 0.60\n",
      "Generation 547 : max score = 0.62\n",
      "Generation 548 : max score = 0.36\n",
      "Generation 549 : max score = 0.40\n",
      "Generation 550 : max score = 0.42\n",
      "Generation 551 : max score = 0.54\n",
      "Generation 552 : max score = 0.44\n",
      "Generation 553 : max score = 0.36\n",
      "Generation 554 : max score = 0.60\n",
      "Generation 555 : max score = 0.40\n",
      "Generation 556 : max score = 0.48\n",
      "Generation 557 : max score = 0.48\n",
      "Generation 558 : max score = 0.58\n",
      "Generation 559 : max score = 0.56\n",
      "Generation 560 : max score = 0.62\n",
      "Generation 561 : max score = 0.54\n",
      "Generation 562 : max score = 0.46\n",
      "Generation 563 : max score = 0.62\n",
      "Generation 564 : max score = 0.56\n",
      "Generation 565 : max score = 0.54\n",
      "Generation 566 : max score = 0.48\n",
      "Generation 567 : max score = 0.66\n",
      "Generation 568 : max score = 0.34\n",
      "Generation 569 : max score = 0.52\n",
      "Generation 570 : max score = 0.52\n",
      "Generation 571 : max score = 0.46\n",
      "Generation 572 : max score = 0.48\n",
      "Generation 573 : max score = 0.44\n",
      "Generation 574 : max score = 0.54\n",
      "Generation 575 : max score = 0.34\n",
      "Generation 576 : max score = 0.48\n",
      "Generation 577 : max score = 0.52\n",
      "Generation 578 : max score = 0.52\n",
      "Generation 579 : max score = 0.36\n",
      "Generation 580 : max score = 0.54\n",
      "Generation 581 : max score = 0.68\n",
      "Generation 582 : max score = 0.46\n",
      "Generation 583 : max score = 0.42\n",
      "Generation 584 : max score = 0.58\n",
      "Generation 585 : max score = 0.44\n",
      "Generation 586 : max score = 0.50\n",
      "Generation 587 : max score = 0.56\n",
      "Generation 588 : max score = 0.54\n",
      "Generation 589 : max score = 0.56\n",
      "Generation 590 : max score = 0.48\n",
      "Generation 591 : max score = 0.64\n",
      "Generation 592 : max score = 0.72\n",
      "Generation 593 : max score = 0.62\n",
      "Generation 594 : max score = 0.52\n",
      "Generation 595 : max score = 0.58\n",
      "Generation 596 : max score = 0.44\n",
      "Generation 597 : max score = 0.56\n",
      "Generation 598 : max score = 0.52\n",
      "Generation 599 : max score = 0.50\n",
      "Generation 600 : max score = 0.46\n",
      "Generation 601 : max score = 0.50\n",
      "Generation 602 : max score = 0.58\n",
      "Generation 603 : max score = 0.62\n",
      "Generation 604 : max score = 0.50\n",
      "Generation 605 : max score = 0.64\n",
      "Generation 606 : max score = 0.54\n",
      "Generation 607 : max score = 0.46\n",
      "Generation 608 : max score = 0.44\n",
      "Generation 609 : max score = 0.38\n",
      "Generation 610 : max score = 0.60\n",
      "Generation 611 : max score = 0.46\n",
      "Generation 612 : max score = 0.58\n",
      "Generation 613 : max score = 0.56\n",
      "Generation 614 : max score = 0.68\n",
      "Generation 615 : max score = 0.44\n",
      "Generation 616 : max score = 0.54\n",
      "Generation 617 : max score = 0.52\n",
      "Generation 618 : max score = 0.50\n",
      "Generation 619 : max score = 0.50\n",
      "Generation 620 : max score = 0.42\n",
      "Generation 621 : max score = 0.64\n",
      "Generation 622 : max score = 0.46\n",
      "Generation 623 : max score = 0.62\n",
      "Generation 624 : max score = 0.44\n",
      "Generation 625 : max score = 0.54\n",
      "Generation 626 : max score = 0.44\n",
      "Generation 627 : max score = 0.40\n",
      "Generation 628 : max score = 0.52\n",
      "Generation 629 : max score = 0.54\n",
      "Generation 630 : max score = 0.52\n",
      "Generation 631 : max score = 0.46\n",
      "Generation 632 : max score = 0.48\n",
      "Generation 633 : max score = 0.56\n",
      "Generation 634 : max score = 0.62\n",
      "Generation 635 : max score = 0.30\n",
      "Generation 636 : max score = 0.54\n",
      "Generation 637 : max score = 0.44\n",
      "Generation 638 : max score = 0.48\n",
      "Generation 639 : max score = 0.56\n",
      "Generation 640 : max score = 0.56\n",
      "Generation 641 : max score = 0.58\n",
      "Generation 642 : max score = 0.58\n",
      "Generation 643 : max score = 0.52\n",
      "Generation 644 : max score = 0.50\n",
      "Generation 645 : max score = 0.52\n",
      "Generation 646 : max score = 0.60\n",
      "Generation 647 : max score = 0.52\n",
      "Generation 648 : max score = 0.50\n",
      "Generation 649 : max score = 0.44\n",
      "Best policy score = 0.36.\n"
     ]
    }
   ],
   "source": [
    "random.seed(4904) # we kick bot\n",
    "np.random.seed(4904)\n",
    "model, env, exp_replay = build_model()\n",
    "## Policy search\n",
    "n_policy = 254\n",
    "n_steps = 649\n",
    "\n",
    "# note to self: the underscore can be used as a throwaway value when iterating through something,\n",
    "# like when you want to do something x times but don't care about the value of x\n",
    "policy_pop = [gen_random_policy() for _ in range(n_policy)]\n",
    "\n",
    "env.reset()\n",
    "env.state\n",
    "policy_pop\n",
    "test_policy = policy_pop[0]\n",
    "\n",
    "# train model\n",
    "for idx in range(n_steps):\n",
    "    policy_scores = [evaluate_policy(env, p) for p in policy_pop]\n",
    "    print('Generation %d : max score = %0.2f' %(idx+1, max(policy_scores)))\n",
    "    policy_ranks = list(reversed(np.argsort(policy_scores)))\n",
    "    elite_set = [policy_pop[x] for x in policy_ranks[:5]]\n",
    "    policy_scores_non_negative = np.array(policy_scores)+1\n",
    "    select_probs = (np.array(policy_scores_non_negative)) / np.sum(policy_scores_non_negative)\n",
    "    child_set = [crossover(\n",
    "        policy_pop[np.random.choice(range(n_policy), p=select_probs)],\n",
    "        policy_pop[np.random.choice(range(n_policy), p=select_probs)])\n",
    "        for _ in range(n_policy - 5)]\n",
    "    mutated_list = [mutation(p) for p in child_set]\n",
    "    policy_pop = elite_set\n",
    "    policy_pop += mutated_list\n",
    "policy_score = [evaluate_policy(env, p) for p in policy_pop]\n",
    "best_policy = policy_pop[np.argmax(policy_score)]\n",
    "\n",
    "print('Best policy score = %0.2f.'\n",
    "        %(np.max(policy_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "for _ in range(200):\n",
    "    run_episode(env, best_policy, exp_replay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_animation(model, env, num_games):\n",
    "    '''\n",
    "    Inputs:\n",
    "        model and env objects as returned from build_model\n",
    "        num_games: integer, the number of games to be included in the animation\n",
    "        \n",
    "    Returns: a matplotlib animation object\n",
    "    '''\n",
    "    # Animation code from \n",
    "    # https://matplotlib.org/examples/animation/dynamic_image.html\n",
    "    # https://stackoverflow.com/questions/35532498/animation-in-ipython-notebook/46878531#46878531\n",
    "    \n",
    "    # First, play the games and collect all of the images for each observed state\n",
    "    observations = []\n",
    "    for _ in range(num_games):\n",
    "        env.reset()\n",
    "        observation = env.observe()\n",
    "        observations.append(observation)\n",
    "        game_over = False\n",
    "        while game_over == False:\n",
    "            q = model.predict(observation)\n",
    "            print(q)\n",
    "            action = np.argmax(q[0])\n",
    "            \n",
    "            # apply action, get rewards and new state\n",
    "            observation, reward, game_over = env.act(action)\n",
    "            observations.append(observation)\n",
    "            \n",
    "    fig = plt.figure()\n",
    "    image = plt.imshow(np.zeros((grid_size, grid_size)),interpolation='none', cmap='gray', animated=True, vmin=0, vmax=1)\n",
    "    \n",
    "    def animate(observation):\n",
    "        image.set_array(observation.reshape((grid_size, grid_size)))\n",
    "        return [image]\n",
    "   \n",
    "    animation = matplotlib.animation.FuncAnimation(fig, animate, frames=observations, blit=True, )\n",
    "    return animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03607967  0.01107605 -0.01688585]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6d23dc22b202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manimation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_animation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_games\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-81766196437f>\u001b[0m in \u001b[0;36mcreate_animation\u001b[0;34m(model, env, num_games)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# apply action, get rewards and new state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame_over\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mobservations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-b930a9aed47f>\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, policy)\u001b[0m\n\u001b[1;32m     75\u001b[0m         '''\n\u001b[1;32m     76\u001b[0m         \u001b[0mfruit_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfruit_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasket_center\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfruit_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfruit_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbasket_center\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BAD\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "animation = create_animation(model, env, num_games=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
